{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d7056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import genome_kit as gk\n",
    "from genome_kit import Genome, Interval, VariantGenome\n",
    "import numpy as np\n",
    "import math\n",
    "from functools import partial\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm.modules.mamba_simple import Mamba, Block\n",
    "from huggingface_hub import PyTorchModelHubMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb7988d-c8aa-479e-a1e4-fa6309032b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer_type</th>\n",
       "      <th>Cancer_type_count</th>\n",
       "      <th>NMF_cluster</th>\n",
       "      <th>build</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>Hugo_Symbol</th>\n",
       "      <th>Transcript_ID</th>\n",
       "      <th>HGVSc</th>\n",
       "      <th>...</th>\n",
       "      <th>AF Group</th>\n",
       "      <th>LOEUF</th>\n",
       "      <th>LOEUF_bin</th>\n",
       "      <th>5UTR_length</th>\n",
       "      <th>3UTR_length</th>\n",
       "      <th>Transcript_length</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>cds_pos</th>\n",
       "      <th>var_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr12</td>\n",
       "      <td>98546362</td>\n",
       "      <td>98546362</td>\n",
       "      <td>TMPO</td>\n",
       "      <td>ENST00000556029</td>\n",
       "      <td>c.994G&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.737</td>\n",
       "      <td>3.0</td>\n",
       "      <td>356</td>\n",
       "      <td>370</td>\n",
       "      <td>1722</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>994</td>\n",
       "      <td>ENST00000556029:c.994G&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACC</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr12</td>\n",
       "      <td>112911070</td>\n",
       "      <td>112911070</td>\n",
       "      <td>OAS1</td>\n",
       "      <td>ENST00000202917</td>\n",
       "      <td>c.489T&gt;G</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>263</td>\n",
       "      <td>715</td>\n",
       "      <td>1467</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>489</td>\n",
       "      <td>ENST00000202917:c.489T&gt;G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACC</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr14</td>\n",
       "      <td>21076448</td>\n",
       "      <td>21076448</td>\n",
       "      <td>ARHGEF40</td>\n",
       "      <td>ENST00000298694</td>\n",
       "      <td>c.1828C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2.0</td>\n",
       "      <td>127</td>\n",
       "      <td>3958</td>\n",
       "      <td>5915</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>1828</td>\n",
       "      <td>ENST00000298694:c.1828C&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACC</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr17</td>\n",
       "      <td>81860411</td>\n",
       "      <td>81860411</td>\n",
       "      <td>P4HB</td>\n",
       "      <td>ENST00000331483</td>\n",
       "      <td>c.61G&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.561</td>\n",
       "      <td>1.0</td>\n",
       "      <td>223</td>\n",
       "      <td>1465</td>\n",
       "      <td>1751</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>61</td>\n",
       "      <td>ENST00000331483:c.61G&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACC</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr1</td>\n",
       "      <td>19219308</td>\n",
       "      <td>19219308</td>\n",
       "      <td>EMC1</td>\n",
       "      <td>ENST00000477853</td>\n",
       "      <td>c.2977C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.000001, 0.00001)</td>\n",
       "      <td>0.914</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>3026</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>2977</td>\n",
       "      <td>ENST00000477853:c.2977C&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>UCS</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr9</td>\n",
       "      <td>34088499</td>\n",
       "      <td>34088499</td>\n",
       "      <td>DCAF12</td>\n",
       "      <td>ENST00000361264</td>\n",
       "      <td>c.1213G&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.699</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342</td>\n",
       "      <td>148</td>\n",
       "      <td>1705</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>1213</td>\n",
       "      <td>ENST00000361264:c.1213G&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>UCS</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr9</td>\n",
       "      <td>79576163</td>\n",
       "      <td>79576163</td>\n",
       "      <td>TLE4</td>\n",
       "      <td>ENST00000376552</td>\n",
       "      <td>c.238G&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018</td>\n",
       "      <td>2083</td>\n",
       "      <td>3341</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>238</td>\n",
       "      <td>ENST00000376552:c.238G&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>UVM</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr14</td>\n",
       "      <td>70342681</td>\n",
       "      <td>70342681</td>\n",
       "      <td>COX16</td>\n",
       "      <td>ENST00000389912</td>\n",
       "      <td>c.118C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.00001, 0.0001)</td>\n",
       "      <td>1.374</td>\n",
       "      <td>7.0</td>\n",
       "      <td>144</td>\n",
       "      <td>202</td>\n",
       "      <td>466</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>118</td>\n",
       "      <td>ENST00000389912:c.118C&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>UVM</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr17</td>\n",
       "      <td>81869230</td>\n",
       "      <td>81869230</td>\n",
       "      <td>ARHGDIA</td>\n",
       "      <td>ENST00000269321</td>\n",
       "      <td>c.358C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.000001, 0.00001)</td>\n",
       "      <td>0.607</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136</td>\n",
       "      <td>256</td>\n",
       "      <td>752</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>358</td>\n",
       "      <td>ENST00000269321:c.358C&gt;T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>UVM</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr16</td>\n",
       "      <td>11752784</td>\n",
       "      <td>11752784</td>\n",
       "      <td>ZC3H7A</td>\n",
       "      <td>ENST00000355758</td>\n",
       "      <td>c.2611C&gt;T</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178</td>\n",
       "      <td>304</td>\n",
       "      <td>3095</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>2611</td>\n",
       "      <td>ENST00000355758:c.2611C&gt;T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4257 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cancer_type  Cancer_type_count  NMF_cluster   build chromosome  \\\n",
       "0            ACC                 12            1  GRCh38      chr12   \n",
       "1            ACC                 12            1  GRCh38      chr12   \n",
       "2            ACC                 12            1  GRCh38      chr14   \n",
       "3            ACC                 12            1  GRCh38      chr17   \n",
       "4            ACC                 12            2  GRCh38       chr1   \n",
       "...          ...                ...          ...     ...        ...   \n",
       "4252         UCS                 40            2  GRCh38       chr9   \n",
       "4253         UCS                 40            2  GRCh38       chr9   \n",
       "4254         UVM                  3            1  GRCh38      chr14   \n",
       "4255         UVM                  3            1  GRCh38      chr17   \n",
       "4256         UVM                  3            3  GRCh38      chr16   \n",
       "\n",
       "          start        end Hugo_Symbol    Transcript_ID      HGVSc  ...  \\\n",
       "0      98546362   98546362        TMPO  ENST00000556029   c.994G>T  ...   \n",
       "1     112911070  112911070        OAS1  ENST00000202917   c.489T>G  ...   \n",
       "2      21076448   21076448    ARHGEF40  ENST00000298694  c.1828C>T  ...   \n",
       "3      81860411   81860411        P4HB  ENST00000331483    c.61G>T  ...   \n",
       "4      19219308   19219308        EMC1  ENST00000477853  c.2977C>T  ...   \n",
       "...         ...        ...         ...              ...        ...  ...   \n",
       "4252   34088499   34088499      DCAF12  ENST00000361264  c.1213G>T  ...   \n",
       "4253   79576163   79576163        TLE4  ENST00000376552   c.238G>T  ...   \n",
       "4254   70342681   70342681       COX16  ENST00000389912   c.118C>T  ...   \n",
       "4255   81869230   81869230     ARHGDIA  ENST00000269321   c.358C>T  ...   \n",
       "4256   11752784   11752784      ZC3H7A  ENST00000355758  c.2611C>T  ...   \n",
       "\n",
       "                 AF Group  LOEUF  LOEUF_bin  5UTR_length  3UTR_length  \\\n",
       "0                     [0]  0.737        3.0          356          370   \n",
       "1                     [0]  0.818        3.0          263          715   \n",
       "2                     [0]  0.722        2.0          127         3958   \n",
       "3                     [0]  0.561        1.0          223         1465   \n",
       "4     [0.000001, 0.00001)  0.914        4.0           43            4   \n",
       "...                   ...    ...        ...          ...          ...   \n",
       "4252                  [0]  0.699        2.0          342          148   \n",
       "4253                  [0]  0.166        0.0         1018         2083   \n",
       "4254    [0.00001, 0.0001)  1.374        7.0          144          202   \n",
       "4255  [0.000001, 0.00001)  0.607        2.0          136          256   \n",
       "4256                  [0]  0.463        1.0          178          304   \n",
       "\n",
       "      Transcript_length  ref  alt  cds_pos                     var_id  \n",
       "0                  1722    G    T      994   ENST00000556029:c.994G>T  \n",
       "1                  1467    T    G      489   ENST00000202917:c.489T>G  \n",
       "2                  5915    C    T     1828  ENST00000298694:c.1828C>T  \n",
       "3                  1751    G    T       61    ENST00000331483:c.61G>T  \n",
       "4                  3026    C    T     2977  ENST00000477853:c.2977C>T  \n",
       "...                 ...  ...  ...      ...                        ...  \n",
       "4252               1705    G    T     1213  ENST00000361264:c.1213G>T  \n",
       "4253               3341    G    T      238   ENST00000376552:c.238G>T  \n",
       "4254                466    C    T      118   ENST00000389912:c.118C>T  \n",
       "4255                752    C    T      358   ENST00000269321:c.358C>T  \n",
       "4256               3095    C    T     2611  ENST00000355758:c.2611C>T  \n",
       "\n",
       "[4257 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/tcga_dataset.csv\") \n",
    "df['ref'] = df['HGVSc'].str.extract(r'[c|g]\\.\\d+([A-Z])>')\n",
    "df['alt'] = df['HGVSc'].str.extract(r'>?([A-Z])$')\n",
    "df['cds_pos'] = df['HGVSc'].str.extract('(\\d+)')\n",
    "df['var_id'] = df['Transcript_ID']+ \":\" + df['HGVSc']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed79777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_genome = Genome(\"gencode.v29\")\n",
    "\n",
    "def find_transcript(genome, transcript_id):\n",
    "    \"\"\"Find a transcript in a genome by transcript ID.\n",
    "    \n",
    "    Args:\n",
    "        genome (object): The genome object containing a list of transcripts.\n",
    "        transcript_id (str): The ID of the transcript to find.\n",
    "        \n",
    "    Returns:\n",
    "        object: The transcript object, if found.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If no transcript with the given ID is found.\n",
    "    \n",
    "    Example:\n",
    "        >>> # Create sample transcripts and a genome\n",
    "        >>> transcript1 = 'ENST00000263946'\n",
    "        >>> genome = Genome(\"gencode.v29\")\n",
    "        >>> result = find_transcript(genome, 'ENST00000335137')\n",
    "        >>> print(result.id)\n",
    "        <Transcript ENST00000263946.7 of PKP1>\n",
    "        >>> # If transcript ID is not found\n",
    "        >>> find_transcript(genome, 'ENST00000000000')\n",
    "        ValueError: Transcript with ID ENST00000000000 not found.\n",
    "    \"\"\"\n",
    "    transcripts = [x for x in genome.transcripts if x.id.split('.')[0] == transcript_id]\n",
    "    if not transcripts:\n",
    "        print(f\"Transcript with ID {transcript_id} not found.\")\n",
    "        return ''\n",
    "    \n",
    "    return transcripts[0]\n",
    "\n",
    "def create_cds_track(t):\n",
    "    \"\"\"Create a track of the coding sequence of a transcript.\n",
    "    Use the exons of the transcript to create a track where the first position of the codon is one.\n",
    "    \n",
    "    Args:\n",
    "        t (gk.Transcript): The transcript object.\n",
    "    \"\"\"\n",
    "    cds_intervals = t.cdss\n",
    "    utr3_intervals = t.utr3s\n",
    "    utr5_intervals = t.utr5s\n",
    "    \n",
    "    len_utr3 = sum([len(x) for x in utr3_intervals])\n",
    "    len_utr5 = sum([len(x) for x in utr5_intervals])\n",
    "    len_cds = sum([len(x) for x in cds_intervals])\n",
    "    \n",
    "    # create a track where first position of the codon is one\n",
    "    cds_track = np.zeros(len_cds, dtype=int)\n",
    "    # set every third position to 1\n",
    "    cds_track[0::3] = 1\n",
    "    # concat with zeros of utr3 and utr5\n",
    "    cds_track = np.concatenate([np.zeros(len_utr5, dtype=int), cds_track, np.zeros(len_utr3, dtype=int)])\n",
    "    return cds_track\n",
    "\n",
    "def create_splice_track(t):\n",
    "    \"\"\"Create a track of the splice sites of a transcript.\n",
    "    The track is a 1D array where the positions of the splice sites are 1.\n",
    "\n",
    "    Args:\n",
    "        t (gk.Transcript): The transcript object.\n",
    "    \"\"\"\n",
    "    len_utr3 = sum([len(x) for x in t.utr3s])\n",
    "    len_utr5 = sum([len(x) for x in t.utr5s])\n",
    "    len_cds = sum([len(x) for x in t.cdss])\n",
    "    \n",
    "    len_mrna = len_utr3 + len_utr5 + len_cds\n",
    "    splicing_track = np.zeros(len_mrna, dtype=int)\n",
    "    cumulative_len = 0\n",
    "    for exon in t.exons:\n",
    "        cumulative_len += len(exon)\n",
    "        splicing_track[cumulative_len - 1:cumulative_len] = 1\n",
    "        \n",
    "    return splicing_track\n",
    "\n",
    "# convert to one hot\n",
    "def seq_to_oh(seq):\n",
    "    oh = np.zeros((len(seq), 4), dtype=int)\n",
    "    for i, base in enumerate(seq):\n",
    "        if base == 'A':\n",
    "            oh[i, 0] = 1\n",
    "        elif base == 'C':\n",
    "            oh[i, 1] = 1\n",
    "        elif base == 'G':\n",
    "            oh[i, 2] = 1\n",
    "        elif base == 'T':\n",
    "            oh[i, 3] = 1\n",
    "    return oh\n",
    "\n",
    "def create_one_hot_encoding(t, genome):\n",
    "    \"\"\"Create a track of the sequence of a transcript.\n",
    "    The track is a 2D array where the rows are the positions\n",
    "    and the columns are the one-hot encoding of the bases.\n",
    "\n",
    "    Args\n",
    "        t (gk.Transcript): The transcript object.\n",
    "    \"\"\"\n",
    "    seq = \"\".join([genome.dna(exon) for exon in t.exons])\n",
    "    oh = seq_to_oh(seq)\n",
    "    return oh\n",
    "\n",
    "def create_six_track_encoding(t, genome, channels_last=False):\n",
    "    \"\"\"Create a track of the sequence of a transcript.\n",
    "    The track is a 2D array where the rows are the positions\n",
    "    and the columns are the one-hot encoding of the bases.\n",
    "    Concatenate the one-hot encoding with the cds track and the splice track.\n",
    "\n",
    "    Args\n",
    "        t (gk.Transcript): The transcript object.\n",
    "    \"\"\"\n",
    "    oh = create_one_hot_encoding(t, genome)\n",
    "    cds_track = create_cds_track(t)\n",
    "    splice_track = create_splice_track(t)\n",
    "    six_track = np.concatenate([oh, cds_track[:, None], splice_track[:, None]], axis=1)\n",
    "    if not channels_last:\n",
    "        six_track = six_track.T\n",
    "    return six_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce26d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_block(\n",
    "    d_model,\n",
    "    ssm_cfg=None,\n",
    "    norm_epsilon=1e-5,\n",
    "    residual_in_fp32=False,\n",
    "    fused_add_norm=False,\n",
    "    layer_idx=None,\n",
    "    device=None,\n",
    "    dtype=None,\n",
    "):\n",
    "    if ssm_cfg is None:\n",
    "        ssm_cfg = {}\n",
    "    factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "    mix_cls = partial(Mamba, layer_idx=layer_idx, **ssm_cfg, **factory_kwargs)\n",
    "    norm_cls = partial(nn.LayerNorm, eps=norm_epsilon, **factory_kwargs)\n",
    "    block = Block(\n",
    "        d_model,\n",
    "        mix_cls,\n",
    "        norm_cls=norm_cls,\n",
    "        fused_add_norm=fused_add_norm,\n",
    "        residual_in_fp32=residual_in_fp32,\n",
    "    )\n",
    "    block.layer_idx = layer_idx\n",
    "    return block\n",
    "\n",
    "\n",
    "class MixerModel(\n",
    "    nn.Module,\n",
    "    PyTorchModelHubMixin,\n",
    "):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        n_layer: int,\n",
    "        input_dim: int,\n",
    "        ssm_cfg=None,\n",
    "        norm_epsilon: float = 1e-5,\n",
    "        rms_norm: bool = False,\n",
    "        initializer_cfg=None,\n",
    "        fused_add_norm=False,\n",
    "        residual_in_fp32=False,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, d_model, **factory_kwargs)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                create_block(\n",
    "                    d_model,\n",
    "                    ssm_cfg=ssm_cfg,\n",
    "                    norm_epsilon=norm_epsilon,\n",
    "                    residual_in_fp32=residual_in_fp32,\n",
    "                    fused_add_norm=fused_add_norm,\n",
    "                    layer_idx=i,\n",
    "                    **factory_kwargs,\n",
    "                )\n",
    "                for i in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.norm_f = nn.LayerNorm(d_model, eps=norm_epsilon, **factory_kwargs)\n",
    "\n",
    "        self.apply(\n",
    "            partial(\n",
    "                _init_weights,\n",
    "                n_layer=n_layer,\n",
    "                **(initializer_cfg if initializer_cfg is not None else {}),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x, inference_params=None, channel_last=False):\n",
    "        if not channel_last:\n",
    "            x = x.transpose(1, 2)\n",
    "\n",
    "        hidden_states = self.embedding(x)\n",
    "        residual = None\n",
    "        for layer in self.layers:\n",
    "            hidden_states, residual = layer(\n",
    "                hidden_states, residual, inference_params=inference_params\n",
    "            )\n",
    "\n",
    "        residual = (hidden_states + residual) if residual is not None else hidden_states\n",
    "        hidden_states = self.norm_f(residual.to(dtype=self.norm_f.weight.dtype))\n",
    "\n",
    "        hidden_states = hidden_states\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "    def representation(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        lengths: torch.Tensor,\n",
    "        aggr: str = \"mean\",\n",
    "        channel_last: bool = False,  \n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Get global representation of input data.\n",
    "\n",
    "        Args:\n",
    "            x: Data to embed. Has shape (B x C x L) if not channel_last.\n",
    "            lengths: Unpadded length of each data input.\n",
    "            aggr: mean, max, or no_aggr\n",
    "            channel_last: Expects input of shape (B x L x C).\n",
    "            \n",
    "        Returns:\n",
    "            Global representation vector of shape (B x H).\n",
    "        \"\"\"\n",
    "        out = self.forward(x, channel_last=channel_last)\n",
    "\n",
    "        if aggr == \"mean\":\n",
    "            embed = mean_unpadded(out, lengths)\n",
    "        if aggr == \"max\":\n",
    "            embed = max_unpadded(out, lengths)\n",
    "        if aggr == \"no_aggr\":\n",
    "            embed = out\n",
    "            \n",
    "        return embed\n",
    "\n",
    "\n",
    "def mean_unpadded(x: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Take mean of tensor across second dimension without padding.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor to take unpadded mean. Has shape (B x L x H).\n",
    "        lengths: Tensor of unpadded lengths. Has shape (B)\n",
    "\n",
    "    Returns:\n",
    "        Mean tensor of shape (B x H).\n",
    "    \"\"\"\n",
    "    mask = torch.arange(x.size(1), device=x.device)[None, :] < lengths[:, None]\n",
    "    masked_tensor = x * mask.unsqueeze(-1)\n",
    "    sum_tensor = masked_tensor.sum(dim=1)\n",
    "    mean_tensor = sum_tensor / lengths.unsqueeze(-1).float()\n",
    "\n",
    "    return mean_tensor\n",
    "\n",
    "\n",
    "def max_unpadded(x: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Take max of tensor across second dimension without padding.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor to take unpadded max. Has shape (B x L x H).\n",
    "        lengths: Tensor of unpadded lengths. Has shape (B)\n",
    "\n",
    "    Returns:\n",
    "        Max tensor of shape (B x H).\n",
    "    \"\"\"\n",
    "    mask = torch.arange(x.size(1), device=x.device)[None, :] < lengths[:, None]\n",
    "    masked_tensor = x * mask.unsqueeze(-1)\n",
    "    # Replace masked out values with a very low value before taking max\n",
    "    #masked_tensor[~mask.unsqueeze(-1)] = float('-inf')\n",
    "    max_tensor, _ = masked_tensor.max(dim=1)\n",
    "    return max_tensor\n",
    "    \n",
    "\n",
    "def _init_weights(\n",
    "    module,\n",
    "    n_layer,\n",
    "    initializer_range=0.02,  # Now only used for embedding layer.\n",
    "    rescale_prenorm_residual=True,\n",
    "    n_residuals_per_layer=1,  # Change to 2 if we have MLP\n",
    "):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if module.bias is not None:\n",
    "            if not getattr(module.bias, \"_no_reinit\", False):\n",
    "                nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "\n",
    "    if rescale_prenorm_residual:\n",
    "        for name, p in module.named_parameters():\n",
    "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
    "                nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                with torch.no_grad():\n",
    "                    p /= math.sqrt(n_residuals_per_layer * n_layer)\n",
    "\n",
    "def load_model(run_path: str, checkpoint_name: str, device='cpu') -> nn.Module:\n",
    "    \"\"\"Load trained model located at specified path.\n",
    "\n",
    "    Args:\n",
    "        run_path: Path where run data is located.\n",
    "        checkpoint_name: Name of model checkpoint to load.\n",
    "\n",
    "    Returns:\n",
    "        Model with loaded weights.\n",
    "    \"\"\"\n",
    "    model_config_path = os.path.join(run_path, \"model_config.json\")\n",
    "    data_config_path = os.path.join(run_path, \"data_config.json\")\n",
    "\n",
    "    with open(model_config_path, \"r\") as f:\n",
    "        model_params = json.load(f)\n",
    "\n",
    "    # TODO: Temp backwards compatibility\n",
    "    if \"n_tracks\" not in model_params:\n",
    "        with open(data_config_path, \"r\") as f:\n",
    "            data_params = json.load(f)\n",
    "        n_tracks = data_params[\"n_tracks\"]\n",
    "    else:\n",
    "        n_tracks = model_params[\"n_tracks\"]\n",
    "\n",
    "    model_path = os.path.join(run_path, checkpoint_name)\n",
    "\n",
    "    model = MixerModel(\n",
    "        d_model=model_params[\"ssm_model_dim\"],\n",
    "        n_layer=model_params[\"ssm_n_layers\"],\n",
    "        input_dim=n_tracks\n",
    "    )\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(device))\n",
    "\n",
    "    state_dict = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        if k.startswith(\"model\"):\n",
    "            state_dict[k.lstrip(\"model\")[1:]] = v\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b334dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixerModel(\n",
       "  (embedding): Linear(in_features=6, out_features=512, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x Block(\n",
       "      (mixer): Mamba(\n",
       "        (in_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
       "        (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)\n",
       "        (act): SiLU()\n",
       "        (x_proj): Linear(in_features=1024, out_features=64, bias=False)\n",
       "        (dt_proj): Linear(in_features=32, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (norm_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint=\"epoch_22_step_20000_new.ckpt\" \n",
    "model_repository=\"/work/gr-fe/saadat/tools/orthrus/Orthrus/HF_model/orthrus_large_6_track/\" \n",
    "model = load_model(f\"{model_repository}\", checkpoint_name=checkpoint, device='cuda')\n",
    "model = model.to(torch.device('cuda'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2b446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeds(transcript_id, genome, aggr):\n",
    "    transc = find_transcript(genome, transcript_id)\n",
    "    sixt = create_six_track_encoding(transc, genome)\n",
    "    sixt = torch.tensor(sixt, dtype=torch.float32)\n",
    "    sixt = sixt.unsqueeze(0)\n",
    "    sixt = sixt.to(device='cuda')\n",
    "    lengths = torch.tensor([sixt.shape[2]]).to(device='cuda')\n",
    "    embedding = model.representation(sixt, lengths, aggr)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "\n",
    "def get_var_genome(row, ref_genome):\n",
    "    nuc_dict = {'A':'T',\n",
    "           'T':'A',\n",
    "           'C':'G',\n",
    "           'G':'C'}\n",
    "    \n",
    "    temp_transc = find_transcript(ref_genome, row['Transcript_ID'])\n",
    "\n",
    "    if temp_transc.strand == '-':\n",
    "        row['ref'] = nuc_dict[row['ref']]\n",
    "        row['alt'] = nuc_dict[row['alt']]\n",
    "        \n",
    "    var_genome = VariantGenome(ref_genome, ref_genome.variant(f\"{row['chromosome']}:{row['start']}:{row['ref']}:{row['alt']}\")) \n",
    "\n",
    "    return var_genome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74359d70-db4f-44e4-a035-698b861e2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n"
     ]
    }
   ],
   "source": [
    "df['var_token_idx'] = None\n",
    "\n",
    "ref_embeds = {}\n",
    "alt_embeds = {}\n",
    "\n",
    "# get embeddings\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    \n",
    "    if index % 100 == 0:\n",
    "        print(index)\n",
    "        \n",
    "    # insert variant\n",
    "    temp_var_genome = get_var_genome(row, ref_genome)\n",
    "\n",
    "    # find index of variant\n",
    "    transc_ref = find_transcript(ref_genome, row['Transcript_ID'])\n",
    "    sixt_ref = create_six_track_encoding(transc_ref, ref_genome)\n",
    "    \n",
    "    transc_alt = find_transcript(temp_var_genome, row['Transcript_ID'])\n",
    "    sixt_alt = create_six_track_encoding(transc_alt, temp_var_genome)\n",
    "\n",
    "    var_token_idx = np.where(~np.all(sixt_alt == sixt_ref, axis=0))[0]\n",
    "\n",
    "    df.loc[index, 'var_token_idx'] = var_token_idx[0]\n",
    "    \n",
    "    # get embeddings\n",
    "    ref_embed = get_embeds(row['Transcript_ID'], ref_genome, 'no_aggr')\n",
    "    alt_embed = get_embeds(row['Transcript_ID'], temp_var_genome, 'no_aggr')\n",
    "\n",
    "    # assign\n",
    "    ref_embeds[row['var_id']] = ref_embed.squeeze().to(torch.bfloat16).detach().cpu()\n",
    "    alt_embeds[row['var_id']] = alt_embed.squeeze().to(torch.bfloat16).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# save df\n",
    "df.to_csv('../data/tcga_processed.tsv.gz', sep='\\t', index=False) \n",
    "\n",
    "# Save as Pickle\n",
    "with open('../data/tcga_ref_embeds.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(ref_embeds, pickle_file)\n",
    "\n",
    "with open('../data/tcga_alt_embeds.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(alt_embeds, pickle_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
