{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0daf2127-73e2-459d-9a30-b1b931f01349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3295df-ec9b-4cda-9a2b-01bc9181e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456a9f42-1dcb-4521-bbb4-69c8abf3ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_features = ['Last exon', 'Last 50nt penultimate exon', 'Exon length longer than 407nt', 'Less than 150nt to start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98b5ff2-d09a-48b4-ab7d-c95f47077983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>build</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>Hugo_Symbol</th>\n",
       "      <th>Transcript_ID</th>\n",
       "      <th>HGVSc</th>\n",
       "      <th>HGVSp</th>\n",
       "      <th>PTC_pos_codon</th>\n",
       "      <th>PTC_to_start_codon</th>\n",
       "      <th>...</th>\n",
       "      <th>var_token_idx</th>\n",
       "      <th>NMD_efficiency</th>\n",
       "      <th>t_vaf</th>\n",
       "      <th>t_depth</th>\n",
       "      <th>n_vaf</th>\n",
       "      <th>n_depth</th>\n",
       "      <th>VAF_RNA</th>\n",
       "      <th>depth_RNA</th>\n",
       "      <th>VAF_DNA_RNA_ratio</th>\n",
       "      <th>tpm_unstranded_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr1</td>\n",
       "      <td>944753</td>\n",
       "      <td>944753</td>\n",
       "      <td>NOC2L</td>\n",
       "      <td>ENST00000327044</td>\n",
       "      <td>c.2191C&gt;T</td>\n",
       "      <td>p.Gln731Ter</td>\n",
       "      <td>731</td>\n",
       "      <td>2193</td>\n",
       "      <td>...</td>\n",
       "      <td>2240</td>\n",
       "      <td>-0.508648</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.422717</td>\n",
       "      <td>76.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr1</td>\n",
       "      <td>952113</td>\n",
       "      <td>952113</td>\n",
       "      <td>NOC2L</td>\n",
       "      <td>ENST00000327044</td>\n",
       "      <td>c.1218G&gt;A</td>\n",
       "      <td>p.Trp406Ter</td>\n",
       "      <td>406</td>\n",
       "      <td>1218</td>\n",
       "      <td>...</td>\n",
       "      <td>1267</td>\n",
       "      <td>1.629509</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.126126</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.323198</td>\n",
       "      <td>49.1731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1255304</td>\n",
       "      <td>1255304</td>\n",
       "      <td>UBE2J2</td>\n",
       "      <td>ENST00000349431</td>\n",
       "      <td>c.679G&gt;T</td>\n",
       "      <td>p.Gly227Ter</td>\n",
       "      <td>227</td>\n",
       "      <td>681</td>\n",
       "      <td>...</td>\n",
       "      <td>898</td>\n",
       "      <td>0.047557</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.464435</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.967573</td>\n",
       "      <td>47.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1338573</td>\n",
       "      <td>1338573</td>\n",
       "      <td>DVL1</td>\n",
       "      <td>ENST00000378888</td>\n",
       "      <td>c.1288G&gt;T</td>\n",
       "      <td>p.Glu430Ter</td>\n",
       "      <td>430</td>\n",
       "      <td>1290</td>\n",
       "      <td>...</td>\n",
       "      <td>1572</td>\n",
       "      <td>1.505167</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.145511</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.352289</td>\n",
       "      <td>50.0535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1387314</td>\n",
       "      <td>1387314</td>\n",
       "      <td>CCNL2</td>\n",
       "      <td>ENST00000400809</td>\n",
       "      <td>c.1480C&gt;T</td>\n",
       "      <td>p.Arg494Ter</td>\n",
       "      <td>494</td>\n",
       "      <td>1482</td>\n",
       "      <td>...</td>\n",
       "      <td>1485</td>\n",
       "      <td>-0.424007</td>\n",
       "      <td>0.407692</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.546980</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.341649</td>\n",
       "      <td>27.1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chrX</td>\n",
       "      <td>152920717</td>\n",
       "      <td>152920717</td>\n",
       "      <td>ZNF185</td>\n",
       "      <td>ENST00000370268</td>\n",
       "      <td>c.622C&gt;T</td>\n",
       "      <td>p.Gln208Ter</td>\n",
       "      <td>208</td>\n",
       "      <td>624</td>\n",
       "      <td>...</td>\n",
       "      <td>658</td>\n",
       "      <td>1.785660</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.290043</td>\n",
       "      <td>52.3474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4089</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chrX</td>\n",
       "      <td>153650171</td>\n",
       "      <td>153650171</td>\n",
       "      <td>DUSP9</td>\n",
       "      <td>ENST00000342782</td>\n",
       "      <td>c.1021G&gt;T</td>\n",
       "      <td>p.Glu341Ter</td>\n",
       "      <td>341</td>\n",
       "      <td>1023</td>\n",
       "      <td>...</td>\n",
       "      <td>1285</td>\n",
       "      <td>-1.360998</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.568627</td>\n",
       "      <td>16.9024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chrX</td>\n",
       "      <td>154030948</td>\n",
       "      <td>154030948</td>\n",
       "      <td>MECP2</td>\n",
       "      <td>ENST00000303391</td>\n",
       "      <td>c.880C&gt;T</td>\n",
       "      <td>p.Arg294Ter</td>\n",
       "      <td>294</td>\n",
       "      <td>882</td>\n",
       "      <td>...</td>\n",
       "      <td>1129</td>\n",
       "      <td>-1.166585</td>\n",
       "      <td>0.406977</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.244797</td>\n",
       "      <td>11.5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chrX</td>\n",
       "      <td>154354015</td>\n",
       "      <td>154354015</td>\n",
       "      <td>FLNA</td>\n",
       "      <td>ENST00000369850</td>\n",
       "      <td>c.5586C&gt;A</td>\n",
       "      <td>p.Tyr1862Ter</td>\n",
       "      <td>1862</td>\n",
       "      <td>5586</td>\n",
       "      <td>...</td>\n",
       "      <td>5834</td>\n",
       "      <td>0.332048</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.794408</td>\n",
       "      <td>63.2541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>GRCh38</td>\n",
       "      <td>chrX</td>\n",
       "      <td>154402790</td>\n",
       "      <td>154402790</td>\n",
       "      <td>DNASE1L1</td>\n",
       "      <td>ENST00000014935</td>\n",
       "      <td>c.826C&gt;T</td>\n",
       "      <td>p.Gln276Ter</td>\n",
       "      <td>276</td>\n",
       "      <td>828</td>\n",
       "      <td>...</td>\n",
       "      <td>1619</td>\n",
       "      <td>3.569856</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>3.9940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4093 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       build chromosome      start        end Hugo_Symbol    Transcript_ID  \\\n",
       "0     GRCh38       chr1     944753     944753       NOC2L  ENST00000327044   \n",
       "1     GRCh38       chr1     952113     952113       NOC2L  ENST00000327044   \n",
       "2     GRCh38       chr1    1255304    1255304      UBE2J2  ENST00000349431   \n",
       "3     GRCh38       chr1    1338573    1338573        DVL1  ENST00000378888   \n",
       "4     GRCh38       chr1    1387314    1387314       CCNL2  ENST00000400809   \n",
       "...      ...        ...        ...        ...         ...              ...   \n",
       "4088  GRCh38       chrX  152920717  152920717      ZNF185  ENST00000370268   \n",
       "4089  GRCh38       chrX  153650171  153650171       DUSP9  ENST00000342782   \n",
       "4090  GRCh38       chrX  154030948  154030948       MECP2  ENST00000303391   \n",
       "4091  GRCh38       chrX  154354015  154354015        FLNA  ENST00000369850   \n",
       "4092  GRCh38       chrX  154402790  154402790    DNASE1L1  ENST00000014935   \n",
       "\n",
       "          HGVSc         HGVSp  PTC_pos_codon  PTC_to_start_codon  ...  \\\n",
       "0     c.2191C>T   p.Gln731Ter            731                2193  ...   \n",
       "1     c.1218G>A   p.Trp406Ter            406                1218  ...   \n",
       "2      c.679G>T   p.Gly227Ter            227                 681  ...   \n",
       "3     c.1288G>T   p.Glu430Ter            430                1290  ...   \n",
       "4     c.1480C>T   p.Arg494Ter            494                1482  ...   \n",
       "...         ...           ...            ...                 ...  ...   \n",
       "4088   c.622C>T   p.Gln208Ter            208                 624  ...   \n",
       "4089  c.1021G>T   p.Glu341Ter            341                1023  ...   \n",
       "4090   c.880C>T   p.Arg294Ter            294                 882  ...   \n",
       "4091  c.5586C>A  p.Tyr1862Ter           1862                5586  ...   \n",
       "4092   c.826C>T   p.Gln276Ter            276                 828  ...   \n",
       "\n",
       "      var_token_idx  NMD_efficiency     t_vaf  t_depth  n_vaf  n_depth  \\\n",
       "0              2240       -0.508648  0.311111     45.0    0.0     43.0   \n",
       "1              1267        1.629509  0.390244     41.0    0.0     14.0   \n",
       "2               898        0.047557  0.480000     50.0    0.0     32.0   \n",
       "3              1572        1.505167  0.413043     46.0    0.0     63.0   \n",
       "4              1485       -0.424007  0.407692    130.0    0.0    152.0   \n",
       "...             ...             ...       ...      ...    ...      ...   \n",
       "4088            658        1.785660  0.328358     67.0    0.0     65.0   \n",
       "4089           1285       -1.360998  0.389313    131.0    0.0    185.0   \n",
       "4090           1129       -1.166585  0.406977     86.0    0.0     70.0   \n",
       "4091           5834        0.332048  0.904762    189.0    0.0    134.0   \n",
       "4092           1619        3.569856  0.339286     56.0    0.0     66.0   \n",
       "\n",
       "       VAF_RNA  depth_RNA VAF_DNA_RNA_ratio tpm_unstranded_x  \n",
       "0     0.442623      244.0          1.422717          76.8018  \n",
       "1     0.126126      111.0          0.323198          49.1731  \n",
       "2     0.464435      239.0          0.967573          47.4110  \n",
       "3     0.145511      323.0          0.352289          50.0535  \n",
       "4     0.546980      298.0          1.341649          27.1883  \n",
       "...        ...        ...               ...              ...  \n",
       "4088  0.095238       42.0          0.290043          52.3474  \n",
       "4089  1.000000       35.0          2.568627          16.9024  \n",
       "4090  0.913580       81.0          2.244797          11.5544  \n",
       "4091  0.718750       32.0          0.794408          63.2541  \n",
       "4092  0.028571      105.0          0.084211           3.9940  \n",
       "\n",
       "[4093 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/tcga_processed.tsv.gz', sep='\\t')\n",
    "\n",
    "### some variants are repeated multiple times\n",
    "df = df.drop(columns=['Cancer_type', 'Cancer_type_count', 'NMF_cluster'])\n",
    "\n",
    "agg_columns = [\n",
    "    'NMD_efficiency', 't_vaf', 't_depth', 'n_vaf', 'n_depth',\n",
    "    'VAF_RNA', 'depth_RNA', 'VAF_DNA_RNA_ratio', 'tpm_unstranded_x'\n",
    "]\n",
    "\n",
    "# Group by all other columns except the ones to aggregate\n",
    "group_by_columns = [col for col in df.columns if col not in agg_columns]\n",
    "\n",
    "# Perform grouping and aggregation without dropping NaNs\n",
    "df_unq = df.groupby(\n",
    "    group_by_columns, dropna=False, as_index=False\n",
    ").agg({col: 'mean' for col in agg_columns})\n",
    "\n",
    "df_unq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ad0f1-e1ce-4c8d-8489-901bf10a88ad",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8add4227-bcca-49df-9b75-21e37850f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ENST00000377813:c.481C>T',\n",
       "  'ENST00000338074:c.2596G>T',\n",
       "  'ENST00000380393:c.1566C>G',\n",
       "  'ENST00000371242:c.781C>T',\n",
       "  'ENST00000370873:c.106C>T'],\n",
       " 232)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_var_ids = df_unq[df_unq['chromosome'].isin(['chr20', 'chr21', 'chr22'])]['var_id'].values.tolist()\n",
    "test_var_ids = list(set(test_var_ids))\n",
    "test_var_ids[0:5], len(test_var_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5df19a0-b8c6-4e15-84ae-1e568a3f54fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ENST00000309311:c.193G>T',\n",
       "  'ENST00000301454:c.310C>T',\n",
       "  'ENST00000541714:c.2695C>T',\n",
       "  'ENST00000309061:c.1594G>T',\n",
       "  'ENST00000250896:c.1105C>T'],\n",
       " 210)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_var_ids = df_unq[df_unq['chromosome']=='chr19']['var_id'].values.tolist()\n",
    "val_var_ids = list(set(val_var_ids))\n",
    "val_var_ids[0:5], len(val_var_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63776dd-b8a3-4be7-8ba2-412e145f5673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ENST00000538716:c.865C>T',\n",
       "  'ENST00000380773:c.1171C>T',\n",
       "  'ENST00000301030:c.5227C>T',\n",
       "  'ENST00000261866:c.6856C>T',\n",
       "  'ENST00000293831:c.931C>T'],\n",
       " 3651)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_var_ids = list(set(df_unq.var_id.values.tolist()) - set(val_var_ids) - set(test_var_ids))\n",
    "train_var_ids[0:5], len(train_var_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12fa2c-2fe1-458b-b802-b40d77d94fae",
   "metadata": {},
   "source": [
    "### loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9225e77-3325-472d-82ab-ad3f598df1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_unq[df_unq['var_id'].isin(train_var_ids)][baseline_features]\n",
    "X_train = X_train.replace({'Yes': 1, 'No': 0})\n",
    "y_train = df_unq[df_unq['var_id'].isin(train_var_ids)]['NMD_efficiency']\n",
    "\n",
    "X_test = df_unq[df_unq['var_id'].isin(test_var_ids)][baseline_features]\n",
    "X_test = X_test.replace({'Yes': 1, 'No': 0})\n",
    "y_test = df_unq[df_unq['var_id'].isin(test_var_ids)]['NMD_efficiency']\n",
    "\n",
    "X_val = df_unq[df_unq['var_id'].isin(val_var_ids)][baseline_features]\n",
    "X_val = X_val.replace({'Yes': 1, 'No': 0})\n",
    "y_val = df_unq[df_unq['var_id'].isin(val_var_ids)]['NMD_efficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d21520-956a-439c-8cf3-34e1fd682158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features.values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef7bda8-ec2e-43a5-b87e-a212dfa535ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bd305-3173-43f0-8c60-f19a9649a485",
   "metadata": {},
   "source": [
    "### train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05d2f02d-8930-4336-b372-757a0ee754bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "HIDDEN_DIMS = [8, 8]\n",
    "DROPOUT = 0.25\n",
    "N_EPOCHS = 50\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "TRANSFORMATION = 'none'  # Options: 'z-score', 'min-max', 'log', 'none'\n",
    "\n",
    "# Evaluation Metrics\n",
    "def evaluate_regression_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy().flatten()\n",
    "    y_pred = y_pred.cpu().numpy().flatten()\n",
    "    loss = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(loss)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        spearman_corr = np.nan\n",
    "        pearson_corr = np.nan\n",
    "    else:\n",
    "        try:\n",
    "            spearman_corr, _ = spearmanr(y_true, y_pred)\n",
    "            pearson_corr, _ = pearsonr(y_true, y_pred)\n",
    "        except ValueError:\n",
    "            spearman_corr = np.nan\n",
    "            pearson_corr = np.nan\n",
    "    \n",
    "    return {\n",
    "        'loss': loss,\n",
    "        'spearman_corr': spearman_corr,\n",
    "        'pearson_corr': pearson_corr,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim, dtype=torch.float32))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, 1, dtype=torch.float32))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Transformation Functions\n",
    "def apply_transformation(y, transformation, stats):\n",
    "    if transformation == 'log':\n",
    "        return torch.log1p(torch.clamp(y - stats['min'] + 1, min=1e-8))\n",
    "    elif transformation == 'z-score':\n",
    "        return (y - stats['mean']) / (stats['std'] + 1e-8)\n",
    "    elif transformation == 'min-max':\n",
    "        return (y - stats['min']) / (stats['max'] - stats['min'] + 1e-8)\n",
    "    return y\n",
    "\n",
    "def inverse_transformation(y, stats, transformation):\n",
    "    if transformation == 'log':\n",
    "        return torch.expm1(y) + stats['min'] - 1\n",
    "    elif transformation == 'z-score':\n",
    "        return y * stats['std'] + stats['mean']\n",
    "    elif transformation == 'min-max':\n",
    "        return y * (stats['max'] - stats['min']) + stats['min']\n",
    "    return y\n",
    "\n",
    "# Calculate Transformation Statistics\n",
    "def calculate_transformation_stats(dataset, transformation):\n",
    "    if transformation == 'none':\n",
    "        return {}\n",
    "    \n",
    "    y = torch.cat([targets for _, targets in dataset], dim=0)\n",
    "    stats = {}\n",
    "    if transformation == 'log':\n",
    "        stats['min'] = y.min()\n",
    "    elif transformation == 'z-score':\n",
    "        stats['mean'] = y.mean()\n",
    "        stats['std'] = y.std()\n",
    "    elif transformation == 'min-max':\n",
    "        stats['min'] = y.min()\n",
    "        stats['max'] = y.max()\n",
    "    return stats\n",
    "\n",
    "# Training Function\n",
    "def train_mlp(train_loader: DataLoader, val_loader: DataLoader, test_loader: DataLoader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    input_dim = next(iter(train_loader))[0].shape[1]\n",
    "    model = MLP(input_dim, HIDDEN_DIMS, DROPOUT).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # Calculate global transformation stats\n",
    "    transformation_stats = calculate_transformation_stats(train_loader, TRANSFORMATION)\n",
    "    \n",
    "    metrics = {'epoch': [], 'phase': [], 'loss': [], 'spearman_corr': [], 'pearson_corr':[], 'mae': [], 'rmse': [], 'r2': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                loader = val_loader\n",
    "            \n",
    "            all_preds, all_targets = [], []\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                for inputs, targets in loader:\n",
    "                    inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device, dtype=torch.float32)\n",
    "                    original_targets = targets.clone()\n",
    "                    \n",
    "                    if TRANSFORMATION != 'none':\n",
    "                        targets = apply_transformation(targets, TRANSFORMATION, transformation_stats)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs).squeeze()\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    all_preds.append(outputs.detach())\n",
    "                    all_targets.append(original_targets.detach())\n",
    "            \n",
    "            epoch_loss = running_loss / len(loader.dataset)\n",
    "            all_preds = torch.cat(all_preds)\n",
    "            all_targets = torch.cat(all_targets)\n",
    "            \n",
    "            if TRANSFORMATION != 'none':\n",
    "                all_preds = inverse_transformation(all_preds, transformation_stats, TRANSFORMATION)\n",
    "            \n",
    "            epoch_metrics = evaluate_regression_metrics(all_targets, all_preds)\n",
    "            epoch_metrics['loss'] = epoch_loss\n",
    "            \n",
    "            # Log metrics\n",
    "            metrics['epoch'].append(epoch)\n",
    "            metrics['phase'].append(phase)\n",
    "            for key, value in epoch_metrics.items():\n",
    "                metrics[key].append(value)\n",
    "            \n",
    "            # Early stopping logic\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    patience_counter = 0\n",
    "                    best_model_state = model.state_dict()\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "                        print(f\"Early stopping at epoch {epoch} with best validation loss: {best_val_loss:.4f}\")\n",
    "                        model.load_state_dict(best_model_state)\n",
    "                        metrics_df = pd.DataFrame(metrics)\n",
    "                        return metrics_df, evaluate_regression_metrics(all_targets, all_preds), model\n",
    "            \n",
    "            # Print metrics every 5 epochs for both phases\n",
    "            if epoch % 5 == 0:\n",
    "                print(\n",
    "                    f\"[Epoch {epoch:03d}] Phase: {phase:5s} | \"\n",
    "                    f\"Loss: {epoch_metrics['loss']:.4f} | \"\n",
    "                    f\"Spearman: {epoch_metrics['spearman_corr']:.4f} | \"\n",
    "                    f\"Pearson: {epoch_metrics['pearson_corr']:.4f} | \"\n",
    "                    f\"MAE: {epoch_metrics['mae']:.4f} | \"\n",
    "                    f\"RMSE: {epoch_metrics['rmse']:.4f} | \"\n",
    "                    f\"R²: {epoch_metrics['r2']:.4f}\"\n",
    "                )\n",
    "    \n",
    "    # Load the best model before final testing\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Final Test Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device, dtype=torch.float32)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            all_preds.append(outputs.detach())\n",
    "            all_targets.append(targets.detach())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    \n",
    "    if TRANSFORMATION != 'none':\n",
    "        all_preds = inverse_transformation(all_preds, transformation_stats, TRANSFORMATION)\n",
    "    \n",
    "    test_metrics = evaluate_regression_metrics(all_targets, all_preds)\n",
    "    print(\n",
    "        \"\\n📊 Final Test Metrics | \"\n",
    "        f\"Loss: {test_metrics['loss']:.4f} | \"\n",
    "        f\"Spearman: {test_metrics['spearman_corr']:.4f} | \"\n",
    "        f\"MAE: {test_metrics['mae']:.4f} | \"\n",
    "        f\"RMSE: {test_metrics['rmse']:.4f} | \"\n",
    "        f\"R²: {test_metrics['r2']:.4f}\"\n",
    "    )\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    return metrics_df, test_metrics, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2dae595-5cbf-47a2-a908-8961d797de71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "[Epoch 005] Phase: train | Loss: 1.4660 | Spearman: 0.3431 | Pearson: 0.3268 | MAE: 0.9494 | RMSE: 1.2108 | R²: 0.0737\n",
      "[Epoch 005] Phase: val   | Loss: 1.3598 | Spearman: 0.6445 | Pearson: 0.5639 | MAE: 0.8726 | RMSE: 1.1661 | R²: 0.2249\n",
      "[Epoch 010] Phase: train | Loss: 1.2483 | Spearman: 0.4972 | Pearson: 0.4701 | MAE: 0.8688 | RMSE: 1.1173 | R²: 0.2112\n",
      "[Epoch 010] Phase: val   | Loss: 1.1841 | Spearman: 0.6518 | Pearson: 0.5906 | MAE: 0.8210 | RMSE: 1.0882 | R²: 0.3251\n",
      "[Epoch 015] Phase: train | Loss: 1.1860 | Spearman: 0.5422 | Pearson: 0.5044 | MAE: 0.8440 | RMSE: 1.0890 | R²: 0.2506\n",
      "[Epoch 015] Phase: val   | Loss: 1.1632 | Spearman: 0.6518 | Pearson: 0.5986 | MAE: 0.8145 | RMSE: 1.0785 | R²: 0.3370\n",
      "[Epoch 020] Phase: train | Loss: 1.1757 | Spearman: 0.5511 | Pearson: 0.5111 | MAE: 0.8383 | RMSE: 1.0843 | R²: 0.2571\n",
      "[Epoch 020] Phase: val   | Loss: 1.1429 | Spearman: 0.6658 | Pearson: 0.6081 | MAE: 0.8065 | RMSE: 1.0691 | R²: 0.3486\n",
      "[Epoch 025] Phase: train | Loss: 1.1769 | Spearman: 0.5491 | Pearson: 0.5103 | MAE: 0.8378 | RMSE: 1.0849 | R²: 0.2563\n",
      "[Epoch 025] Phase: val   | Loss: 1.1386 | Spearman: 0.6755 | Pearson: 0.6096 | MAE: 0.8056 | RMSE: 1.0671 | R²: 0.3510\n",
      "[Epoch 030] Phase: train | Loss: 1.1508 | Spearman: 0.5573 | Pearson: 0.5251 | MAE: 0.8278 | RMSE: 1.0728 | R²: 0.2728\n",
      "[Epoch 030] Phase: val   | Loss: 1.1350 | Spearman: 0.6755 | Pearson: 0.6090 | MAE: 0.8042 | RMSE: 1.0654 | R²: 0.3531\n",
      "[Epoch 035] Phase: train | Loss: 1.1276 | Spearman: 0.5653 | Pearson: 0.5379 | MAE: 0.8200 | RMSE: 1.0619 | R²: 0.2875\n",
      "[Epoch 035] Phase: val   | Loss: 1.1371 | Spearman: 0.6755 | Pearson: 0.6082 | MAE: 0.8053 | RMSE: 1.0664 | R²: 0.3519\n",
      "[Epoch 040] Phase: train | Loss: 1.1398 | Spearman: 0.5571 | Pearson: 0.5310 | MAE: 0.8235 | RMSE: 1.0676 | R²: 0.2798\n",
      "[Epoch 040] Phase: val   | Loss: 1.1400 | Spearman: 0.6750 | Pearson: 0.6061 | MAE: 0.8049 | RMSE: 1.0677 | R²: 0.3502\n",
      "Early stopping at epoch 44 with best validation loss: 1.1341\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "print(\"START TRAINING\")\n",
    "metrics_df, test_metrics, model = train_mlp(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc52fbf7-b26b-4f08-acad-afade501b9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_test_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>1.136854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>0.804565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pearson_corr</th>\n",
       "      <td>0.604776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.352013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>1.066234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_corr</th>\n",
       "      <td>0.674507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               baseline_test_metrics\n",
       "loss                        1.136854\n",
       "mae                         0.804565\n",
       "pearson_corr                0.604776\n",
       "r2                          0.352013\n",
       "rmse                        1.066234\n",
       "spearman_corr               0.674507"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.to_csv('../res/metrics/baseline/per_epoch_metric.csv', index=False)\n",
    "\n",
    "test_metrics_df = pd.DataFrame({'baseline_test_metrics':test_metrics})\n",
    "test_metrics_df.to_csv('../res/metrics/baseline/test_metrics.csv', index=False)\n",
    "test_metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
